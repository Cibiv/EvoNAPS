{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pathlib\n",
    "from os import path\n",
    "import sys\n",
    "import mysql.connector as mysql\n",
    "import pandas as pd\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "from update_alignment_taxonomy import get_alignment_taxonomy, get_taxonomy, taxonomic_hierarchy_per_sequence\n",
    "\n",
    "class Data:\n",
    "\n",
    "    def __init__(self, db_credentials:pathlib.Path, output:str, quiet = False):\n",
    "        \n",
    "        self.read_db_credentials(db_credentials)\n",
    "        self.log_file = output\n",
    "        self.quiet = quiet\n",
    "        self.taxonomy_tbl = get_taxonomy(self.db_config)\n",
    "\n",
    "    def merge_taxon_ids(self, ncbi:pathlib.Path):\n",
    "\n",
    "        nodes = pd.read_csv(ncbi, sep='\\t')\n",
    "        nodes = nodes.rename(columns={'tax_id':'TAX_ID', 'parent_tax_id': 'PARENT_TAX_ID_new', 'rank': 'TAX_RANK_new', 'name_txt': 'TAX_NAME_new'})\n",
    "        taxonomy_tbl = self.taxonomy_tbl\n",
    "        taxonomy_tbl = taxonomy_tbl.reset_index()\n",
    "        taxonomy_tbl = taxonomy_tbl.rename(columns={'PARENT_TAX_ID': 'PARENT_TAX_ID_old', 'TAX_NAME': 'TAX_NAME_old', 'TAX_RANK':'TAX_RANK_old'})\n",
    "        self.merged_tax = taxonomy_tbl.merge(nodes, how='outer', on='TAX_ID')\n",
    "\n",
    "    def read_db_credentials(self, file:pathlib.Path):\n",
    "        '''Reads in credentials file and returns dictionary holding the credentials.'''\n",
    "\n",
    "        credentials = {}\n",
    "        if path.exists(file) == False:\n",
    "            print(f'ERROR: Could not find db credentials file: {file}!')\n",
    "            sys.exit(2)\n",
    "\n",
    "        with open(file, 'r') as t:\n",
    "            lines = [line.strip().split('=') for line in t]\n",
    "\n",
    "        for i in range (len(lines)):\n",
    "            credentials[lines[i][0]] = lines[i][1]\n",
    "\n",
    "        for key in ['host', 'user', 'password', 'database']:\n",
    "            if key not in credentials.keys():\n",
    "                print(f'Credential {key} is missing form credential file {file}')\n",
    "                sys.exit(2)\n",
    "\n",
    "        self.db_config = {\n",
    "            \"host\": credentials['host'],\n",
    "            \"user\": credentials['user'],\n",
    "            \"password\": credentials['password'],\n",
    "            \"database\": credentials['database'], \n",
    "            \"allow_local_infile\": True \n",
    "        }\n",
    "\n",
    "    def _compare_row(self, row):\n",
    "        if int(row['PARENT_TAX_ID_old']) != int(row['PARENT_TAX_ID_new']):\n",
    "            #print(f'{int(row['PARENT_TAX_ID_old'])}, {int(row['PARENT_TAX_ID_new'])}')\n",
    "            return False\n",
    "        if row['TAX_NAME_old'] != row['TAX_NAME_new']:\n",
    "            #print(f'{row['TAX_NAME_old']}, {row['TAX_NAME_new']}')\n",
    "            return False\n",
    "        if row['TAX_RANK_old'] != row['TAX_RANK_new']:\n",
    "            #print(f'{row['TAX_RANK_old']}, {row['TAX_RANK_new']}')\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def compare(self):\n",
    "\n",
    "        self.merged_tax['TO_DO'] = 'nothing'\n",
    "\n",
    "        for index, row in self.merged_tax.iterrows():\n",
    "            if np.isnan(row['PARENT_TAX_ID_old']):\n",
    "                self.merged_tax.at[index, 'TO_DO'] = 'insert'\n",
    "\n",
    "            elif not np.isnan(row['PARENT_TAX_ID_new']) and self._compare_row(row) is False:\n",
    "                self.merged_tax.at[index, 'TO_DO'] = 'update'\n",
    "\n",
    "            elif np.isnan(row['PARENT_TAX_ID_new']):\n",
    "                self.merged_tax.at[index, 'TO_DO'] = 'delete'\n",
    "\n",
    "def qprint(comment:str, quiet=False) -> None:\n",
    "    if quiet is True:\n",
    "        print(comment)\n",
    "    return\n",
    "\n",
    "def run_query(data:Data, query, params):\n",
    "\n",
    "    info = {}\n",
    "    \n",
    "    # Configure logging\n",
    "    logging.basicConfig(filename=data.log_file, level=logging.INFO, \n",
    "                        format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "    \n",
    "    logging.info(f'Executing query: {query} with parameters: {params}')\n",
    "\n",
    "    # MySQL connection\n",
    "    try:\n",
    "        conn = mysql.connect(**data.db_config)\n",
    "        cursor = conn.cursor(buffered=True)\n",
    "\n",
    "        # Enable local infile if needed\n",
    "        cursor.execute(\"SET GLOBAL local_infile = 1;\")\n",
    "\n",
    "        # Execute the query\n",
    "        if params:\n",
    "            cursor.execute(query, params)\n",
    "        else:\n",
    "            cursor.execute(query)\n",
    "\n",
    "        # Log affected rows\n",
    "        info['affected'] = cursor.rowcount\n",
    "\n",
    "        # Fetch number of matched rows and warnings\n",
    "        cursor.execute(\"SHOW WARNINGS;\")\n",
    "        warnings = cursor.fetchall()\n",
    "        info['warning'] = len(warnings)\n",
    "\n",
    "        # Log and print warnings\n",
    "        if warnings:\n",
    "            for warning in warnings:\n",
    "                log_msg = f\"{warning}\"\n",
    "                logging.warning(log_msg)\n",
    "                qprint(log_msg, quiet=data.quiet)\n",
    "\n",
    "        logging.info(f\"Affected Rows: {info['affected']}, \\\n",
    "Number of Warnings: {info['warning']}\")\n",
    "\n",
    "        # Commit changes\n",
    "        conn.commit()\n",
    "\n",
    "    except mysql.Error as err:\n",
    "        log_msg = f\"{err}\"\n",
    "        logging.error(log_msg)\n",
    "        print(log_msg)\n",
    "        sys.exit(2)\n",
    "\n",
    "    finally:\n",
    "        # Check if cursor and connection exist before closing\n",
    "        if 'cursor' in locals() and cursor:\n",
    "            cursor.close()\n",
    "        if 'conn' in locals() and conn:\n",
    "            conn.close()\n",
    "\n",
    "def read_merged_file(merged):\n",
    "\n",
    "    with open(merged) as t:\n",
    "        lines = t.readlines()\n",
    "\n",
    "    for i in range (len(lines)):\n",
    "        lines[i] = lines[i].split('|')\n",
    "        for j in range (len(lines[i])):\n",
    "            lines[i][j] = lines[i][j].strip()\n",
    "    \n",
    "    merged_dict = {}\n",
    "    for i in range (len(lines)):\n",
    "        merged_dict[int(lines[i][0])] = int(lines[i][1])\n",
    "\n",
    "    return merged_dict\n",
    "\n",
    "def check_sequences(data:Data, tax_id, seq_type = 'DNA'):\n",
    "    \n",
    "    mydb = mysql.connect(**data.db_config)\n",
    "\n",
    "    mycursor = mydb.cursor()\n",
    "    query = f\"SELECT ALI_ID FROM {seq_type.lower()}_sequences WHERE TAX_ID={tax_id};\"\n",
    "\n",
    "    mycursor.execute(query)\n",
    "    myresult = mycursor.fetchall()\n",
    "\n",
    "    df = pd.DataFrame(myresult, columns = ['ALI_ID'])\n",
    "\n",
    "    # Reindex taxonomy table to allow for faster lookups.\n",
    "    return list(df['ALI_ID'])\n",
    "\n",
    "def insert_new(data:Data, file_name):\n",
    "\n",
    "    query = f\"LOAD DATA LOCAL INFILE '{file_name}' IGNORE INTO TABLE taxonomy FIELDS \\\n",
    "TERMINATED BY '\\t' OPTIONALLY ENCLOSED BY '\\\"' LINES TERMINATED BY '\\n' IGNORE 1 LINES (\\\n",
    "TAX_ID, PARENT_TAX_ID, TAX_NAME, TAX_RANK);\"\n",
    "    run_query(data, query, None)\n",
    "\n",
    "def update_tax(data:Data):\n",
    "\n",
    "    for idx, row in data.merged_tax[data.merged_tax['TO_DO']=='update'].iterrows():\n",
    "        query = f'UPDATE taxonomy SET PARENT_TAX_ID=%s, TAX_NAME=%s, TAX_RANK=%s WHERE TAX_ID=%s;'\n",
    "        params = (row['PARENT_TAX_ID_new'], row['TAX_NAME_new'], row['TAX_RANK_new'], row['TAX_ID'])\n",
    "        run_query(data, query, params)\n",
    "\n",
    "def merge_and_check(data:Data):\n",
    "\n",
    "    affected_tax_ids = []\n",
    "    for idx, row in data.merged_tax[data.merged_tax['TO_DO']=='delete'].iterrows():\n",
    "        old_id = row['TAX_ID']\n",
    "\n",
    "        # Check if the tax_id is present in a sequence table\n",
    "        for seq_type in ['dna', 'aa']:\n",
    "            seq_df = check_sequences(data, row['TAX_ID'], seq_type=seq_type)\n",
    "            if len(seq_df) > 0:\n",
    "                # If can be merged, update sequence table\n",
    "                if old_id in data.merged_dict.keys():\n",
    "                    query = f'UPDATE {seq_type}_sequences SET TAX_ID=%s WHERE TAX_ID=%s;'\n",
    "                    params = (data.merged_dict[old_id], old_id)\n",
    "                    run_query(data, query, params)\n",
    "                else:\n",
    "                    if old_id not in affected_tax_ids:\n",
    "                        affected_tax_ids.append(old_id)\n",
    "\n",
    "    # Return tax_ids, that need to be further updated\n",
    "    return affected_tax_ids\n",
    "\n",
    "def find_tax_id(data:Data, tax_ids:list) -> None:\n",
    "\n",
    "    taxonomy_tbl = get_taxonomy(data.db_config)\n",
    "\n",
    "    sub_tax = data.merged_tax[data.merged_tax['TO_DO'] != 'delete']\n",
    "    for tax_id in tax_ids:\n",
    "        # Get taxonomic hierachy\n",
    "        hierachy = taxonomic_hierarchy_per_sequence(tax_id, taxonomy_tbl)\n",
    "        check = False\n",
    "        index = len(hierachy['TAX_ID'])-1\n",
    "        # Check hierachy to find a tax_id, which is still in the database\n",
    "        while index > 0:\n",
    "            if hierachy['TAX_ID'][index] in sub_tax['TAX_ID'].to_list():\n",
    "                for seq_type in ['dna', 'aa']:\n",
    "                    query = f\"UPDATE {seq_type.lower()}_sequences SET TAX_ID=%s WHERE TAX_ID=%s;\"\n",
    "                    params = (int(hierachy['TAX_ID'][index]), int(tax_id))\n",
    "                    run_query(data, query, params)\n",
    "                    check = True\n",
    "                break\n",
    "            index -= 1\n",
    "\n",
    "        # If none is found, set TAX_ID to 1 and TAX_CHECK to 0.\n",
    "        if check is False:\n",
    "            for seq_type in ['dna', 'aa']:\n",
    "                query = f\"UPDATE {seq_type.lower()}_sequences SET TAX_ID=1, TAX_CHECK=0 WHERE TAX_ID=%s;\"\n",
    "                params = (tax_id)\n",
    "                print(f'WARNING: {tax_id} could not be resolved. Sequence tax_id will be set to 1!')\n",
    "                run_query(data, query, params)\n",
    "\n",
    "def delete_tax(data:Data) -> None:\n",
    "\n",
    "    for seq_type in ['dna', 'aa']:\n",
    "        query = f\"TRUNCATE TABLE {seq_type.lower()}_alignments_taxonomy;\"\n",
    "        run_query(data, query, None)\n",
    "\n",
    "    for idx, row in data.merged_tax[data.merged_tax['TO_DO']=='delete'].iterrows():\n",
    "        old_id = row['TAX_ID']\n",
    "        query = f'DELETE FROM taxonomy where TAX_ID=%s;'\n",
    "        params = (int(old_id),)\n",
    "        run_query(data, query, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data('EvoNAPS_credentials.cnf', 'update_taxonomy.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.merged_dict = read_merged_file('/home/frareden/.ncbi_tax/taxdmp/merged.dmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unchanged: 2650134\n",
      "Insertion: 0\n",
      "Update: 0\n",
      "Delete: 11090\n"
     ]
    }
   ],
   "source": [
    "data.merge_taxon_ids('/home/frareden/.ncbi_tax/nodes.tsv')\n",
    "data.compare()\n",
    "\n",
    "print(f'Unchanged: {len(data.merged_tax[data.merged_tax['TO_DO']=='nothing'])}')\n",
    "print(f'Insertion: {len(data.merged_tax[data.merged_tax['TO_DO']=='insert'])}')\n",
    "print(f'Update: {len(data.merged_tax[data.merged_tax['TO_DO']=='update'])}')\n",
    "print(f'Delete: {len(data.merged_tax[data.merged_tax['TO_DO']=='delete'])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = data.merged_tax[data.merged_tax['TO_DO']=='insert']\n",
    "\n",
    "with open('to_insert.tsv', 'w') as w:\n",
    "    w.write('TAX_ID\\tPARENT_TAX_ID\\tTAX_NAME\\tTAX_RANK\\n')\n",
    "    for idx in new_data.index:\n",
    "        w.write(f'{new_data.at[idx, 'TAX_ID']}\\t')\n",
    "        w.write(f'{new_data.at[idx, 'PARENT_TAX_ID_new']}\\t')\n",
    "        w.write(f'{new_data.at[idx, 'TAX_NAME_new']}\\t')\n",
    "        w.write(f'{new_data.at[idx, 'TAX_RANK_new']}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_new(data, 'to_insert.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_tax(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "affected_tax_ids = merge_and_check(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affected_tax_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_tax_id(data, affected_tax_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_tax(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evonaps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
